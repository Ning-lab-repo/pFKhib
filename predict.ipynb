{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d33af7-3439-4223-b5c6-ecdf982d248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03646e4c-8d15-40e7-b34d-64913b2ef001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col1(fn):\n",
    "    finame = r'E:/NingLab/object/khib/transfer/experiment/' + str.upper(fn) + r'/A0A0G2JSG6_28.' + str.lower(fn)\n",
    "    with open(finame) as file:\n",
    "        values = file.read().rstrip().split('\\t')\n",
    "        i = 0\n",
    "        columns = []\n",
    "        while i < len(values):\n",
    "            columns.append(str(i))\n",
    "            i += 1\n",
    "    return columns, len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db2ed31-7d4a-4c7e-a318-0e2d6ccc2da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset1(feature_name):\n",
    "    global dataset\n",
    "    col, size = get_col1(feature_name)\n",
    "    x = dataset[col]\n",
    "    ID = dataset['pepname']\n",
    "    return x, ID, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "652c345c-b3a5-4915-b077-02c4440eddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBC\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBC\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBC\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBC\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBC\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "feature_list = ['OBC']\n",
    "for feature in feature_list:\n",
    "    for count in range(1, 6):  # 从1到5遍历count\n",
    "        model = load_model(f'E:/NingLab/object/khib/transfer/models/DNN/%s/%s_DNN_%d.h5' % (feature, feature, count))\n",
    "        dataset = pd.read_csv(f'E:/NingLab/object/khib/transfer/experiment/%s_dataset.csv' % feature)\n",
    "        data, peplist, data_size = prep_dataset1(feature)\n",
    "        print(feature)\n",
    "        y_score = model.predict(data)\n",
    "        df_y = pd.concat([pd.DataFrame(list(peplist), columns=['pepname']),\n",
    "                          pd.DataFrame(list(y_score), columns=['score'])], axis=1)\n",
    "        path = f'E:/NingLab/object/khib/transfer/DNN_result_for_experiment/'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        df_y.to_csv(f'{path}{feature}_scores_{count}.csv', index=False)\n",
    "        #df_y.to_csv(path + f'%s_scores_%.csv' % (feature,count), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f8ce8f2-8e7d-4c1a-9466-6107ee335633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN1中'A0A0G2JSH2'的得分为：0.82365346，排名为：221\n",
      "DNN2中'A0A0G2JSH2'的得分为：0.84729797，排名为：247\n",
      "DNN3中'A0A0G2JSH2'的得分为：0.89957815，排名为：132\n",
      "DNN4中'A0A0G2JSH2'的得分为：0.6336696，排名为：538\n",
      "DNN5中'A0A0G2JSH2'的得分为：0.79046834，排名为：399\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 存储'A0A0G2JSH2'的得分和排名\n",
    "scores_and_ranks = []\n",
    "\n",
    "for count in range(1, 6):\n",
    "    # 加载CSV文件\n",
    "    df = pd.read_csv(f'E:/NingLab/object/khib/transfer/DNN_result_for_experiment/OBC_scores_{count}.csv')\n",
    "    \n",
    "    # 筛选出'A0A0G2JSH2'的得分\n",
    "    score = df[df['pepname'] == 'A0A0G2JSH2_74']['score'].values[0]\n",
    "    \n",
    "    # 计算排名\n",
    "    ranks = df['score'].rank(ascending=False).astype(int)\n",
    "    rank_of_A0A0G2JSH2 = ranks[df[df['pepname'] == 'A0A0G2JSH2_74'].index[0]]\n",
    "    \n",
    "    # 将得分和排名加入到列表中\n",
    "    scores_and_ranks.append((score, rank_of_A0A0G2JSH2))\n",
    "\n",
    "# 打印结果\n",
    "for count, (score, rank) in enumerate(scores_and_ranks, start=1):\n",
    "    print(f\"DNN{count}中'A0A0G2JSH2'的得分为：{score}，排名为：{rank}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "011cb845-a0db-45df-985b-0e8daa414598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.90 132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70aa32a-4dc8-48c3-a05d-8bcf86472dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4249cf6f-5827-4b71-96e4-fdd7635b0d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4865e858-944a-4bb3-af89-222e440059eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_11(fileplace):\n",
    "    features = ['ACF', 'ASA', 'AAINDEX', 'BTA', 'CKSAAP', 'GPS', 'OBC', 'PSEAAC', 'PSSM', 'SS', 'transformer']\n",
    "    scorelist = []\n",
    "    \n",
    "    # 读取第一个文件以获得pepname\n",
    "    first_file = fileplace + r'/' + features[0] + r'.csv'\n",
    "    df_first = pd.read_csv(first_file)\n",
    "    peptidenames = df_first['pepname']\n",
    "    \n",
    "    # 初始化一个 DataFrame 来保存所有的分数\n",
    "    all_scores = pd.DataFrame(peptidenames, columns=['pepname'])\n",
    "    \n",
    "    # 处理每个文件\n",
    "\n",
    "    for feature in features:\n",
    "        df = pd.read_csv(fileplace + r'/' + feature + r'.csv')\n",
    "        # 根据 pepname 进行匹配和添加分数\n",
    "        df = df[df['pepname'].isin(peptidenames)]\n",
    "        df = df[['pepname', 'score']]\n",
    "        all_scores = pd.merge(all_scores, df, on='pepname', how='left', suffixes=('', f'_{feature}'))\n",
    "    \n",
    "    # 将分数列提取出来\n",
    "    score_columns = [col for col in all_scores.columns if col != 'pepname']\n",
    "    \n",
    "    # 提取所有的分数列\n",
    "    scorelist = all_scores[score_columns].values\n",
    "    \n",
    "    return np.array(scorelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64661fde-6a63-4b56-a183-2f6ac469686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_and_label():\n",
    "    df = pd.read_csv('E:/NingLab/object/khib/transfer/DNN_result_for_experiment/score/ASA.csv')\n",
    "    name = df['pepname']\n",
    "    name = name.values\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37f3ec19-61c2-4a9e-9ddd-67a3739b0555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    }
   ],
   "source": [
    "for count in range(1, 6):\n",
    "    data = auc_11('E:/NingLab/object/khib/transfer/DNN_result_for_experiment/score')\n",
    "    iDNN = load_model(f'E:/NingLab/object/khib/transfer/models/integrated_DNN/iDNN_%d.h5' % count)\n",
    "    #iDNN = load_model(f'E:/QD065LPSc/Ksuc/models/integrated_DNN/iDNN_%d.h5' % count)\n",
    "    score = iDNN.predict(data)\n",
    "    peplist = get_name_and_label()\n",
    "    df_y = pd.concat([pd.DataFrame(list(peplist), columns=['pepname']),\n",
    "                  pd.DataFrame(list(score), columns=['score'])], axis=1)\n",
    "    df_y.to_csv(f'E:/NingLab/object/khib/transfer/models/iDNN_%d_result_for_experiment.csv' % count, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a5f5f99-729c-406b-9ad3-ab4ea2674f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iDNN1中'A0A0G2JSH2'的得分为：0.7017485，排名为：1\n",
      "iDNN2中'A0A0G2JSH2'的得分为：0.563576，排名为：16\n",
      "iDNN3中'A0A0G2JSH2'的得分为：0.44146675，排名为：56\n",
      "iDNN4中'A0A0G2JSH2'的得分为：0.20108594，排名为：325\n",
      "iDNN5中'A0A0G2JSH2'的得分为：0.22744238，排名为：284\n"
     ]
    }
   ],
   "source": [
    "# 存储'A0A0G2JSH2'的得分和排名\n",
    "scores_and_ranks = []\n",
    "\n",
    "for count in range(1, 6):\n",
    "    # 加载CSV文件\n",
    "   \n",
    "    df = pd.read_csv(f'E:/NingLab/object/khib/transfer/models/iDNN_%d_result_for_experiment.csv' % count)\n",
    "    \n",
    "    # 筛选出'A0A0G2JSH2'的得分\n",
    "    score = df[df['pepname'] == 'A0A0G2JSH2_74']['score'].values[0]\n",
    "    \n",
    "    # 计算排名\n",
    "    ranks = df['score'].rank(ascending=False).astype(int)\n",
    "    rank_of_A0A0G2JSH2 = ranks[df[df['pepname'] == 'A0A0G2JSH2_74'].index[0]]\n",
    "    \n",
    "    # 将得分和排名加入到列表中\n",
    "    scores_and_ranks.append((score, rank_of_A0A0G2JSH2))\n",
    "\n",
    "# 打印结果\n",
    "for count, (score, rank) in enumerate(scores_and_ranks, start=1):\n",
    "    print(f\"iDNN{count}中'A0A0G2JSH2'的得分为：{score}，排名为：{rank}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54197a3-1d68-4143-af65-7445c8318a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
