{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be772184-09b2-4c5c-a37b-fe775d68e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import clone_model\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca7b9ef-a595-41b2-9c47-0b407ac94eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_location, featuretype, modeltype):\n",
    "    t_model = load_model('%s/%s/%s/%s_%s_%d.h5' % (model_location, modeltype, featuretype, str.upper(featuretype),\n",
    "                                                   modeltype,\n",
    "                                                   np.random.randint(1, 6)\n",
    "                                                   ))\n",
    "    return t_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8afd318b-801a-48ff-b510-272a2d5aef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(featuretype, modeltype):\n",
    "    df = pd.read_csv(f'./%s_dataset.csv' % featuretype)\n",
    "    pepnames = df['pepname']\n",
    "    labels = df['label']\n",
    "    if modeltype == 'DNN':\n",
    "        dataset = df.drop(labels=['pepname', 'label'], axis=1)\n",
    "    elif modeltype == 'CNN':\n",
    "        dataset = []\n",
    "        for pepname in pepnames:\n",
    "            img = Image.open(r'./2D_dataset/' + featuretype + r'/' + pepname + r'.png')\n",
    "            img = np.array(img)\n",
    "            img = img / 256\n",
    "            dataset.append(img)\n",
    "    return pepnames, np.array(dataset), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9b11e35-8098-46be-8a4c-c217d1f7caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_your_data(training_labels):\n",
    "    num_pos = 0\n",
    "    num_neg = 0\n",
    "    for training_label in training_labels:\n",
    "        if training_label == 0:\n",
    "            num_neg += 1\n",
    "        else:\n",
    "            num_pos += 1\n",
    "    pos_times = np.float64(num_neg / num_pos)\n",
    "    return {0: 1., 1: pos_times}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c98a461f-c71e-417f-85c7-457e890c8491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportion(tr_labels):\n",
    "    n_pos = 0\n",
    "    for tr_label in tr_labels:\n",
    "        if tr_label != 0:\n",
    "            n_pos += 1\n",
    "    return np.float64(n_pos / len(tr_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34402962-dea6-4d6b-91eb-94335784dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def reset_keras():\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a31f58-a124-48ba-8de8-f695bfbc04c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————————OBC DNN——————————————\n",
      "Epoch 1/10\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - acc: 0.4953 - loss: 1.9696\n",
      "Epoch 2/10\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - acc: 0.5017 - loss: 1.6795\n",
      "Epoch 3/10\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - acc: 0.5021 - loss: 1.6331\n",
      "Epoch 4/10\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - acc: 0.4991 - loss: 1.6217\n",
      "Epoch 5/10\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - acc: 0.5016 - loss: 1.5947\n",
      "Epoch 6/10\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - acc: 0.5055 - loss: 1.5861\n",
      "Epoch 7/10\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - acc: 0.5104 - loss: 1.5774\n",
      "Epoch 8/10\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - acc: 0.5115 - loss: 1.5670\n",
      "Epoch 9/10\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - acc: 0.5201 - loss: 1.5466\n",
      "Epoch 10/10\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - acc: 0.5166 - loss: 1.5413\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step\n",
      "第1个OBC的DNN模型的ROCAUC分数为： 0.6570300832088757\n",
      "第1个OBC的DNN模型的PRAUC分数为： 0.0014849424457169763\n",
      "Epoch 1/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - acc: 0.4993 - loss: 2.2432\n",
      "Epoch 2/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - acc: 0.4975 - loss: 1.7001\n",
      "Epoch 3/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - acc: 0.4999 - loss: 1.6637\n",
      "Epoch 4/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - acc: 0.5024 - loss: 1.6395\n",
      "Epoch 5/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - acc: 0.5025 - loss: 1.6346\n",
      "Epoch 6/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - acc: 0.5036 - loss: 1.6218\n",
      "Epoch 7/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - acc: 0.5040 - loss: 1.6158\n",
      "Epoch 8/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - acc: 0.5001 - loss: 1.6182\n",
      "Epoch 9/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - acc: 0.4983 - loss: 1.6187\n",
      "Epoch 10/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - acc: 0.4988 - loss: 1.6098\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step\n",
      "第2个OBC的DNN模型的ROCAUC分数为： 0.31150455062571103\n",
      "第2个OBC的DNN模型的PRAUC分数为： 0.0004283642808998904\n",
      "Epoch 1/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - acc: 0.5035 - loss: 2.0431\n",
      "Epoch 2/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - acc: 0.5019 - loss: 1.7068\n",
      "Epoch 3/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - acc: 0.4972 - loss: 1.6912\n",
      "Epoch 4/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - acc: 0.4972 - loss: 1.6636\n",
      "Epoch 5/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - acc: 0.4964 - loss: 1.6476\n",
      "Epoch 6/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - acc: 0.5035 - loss: 1.6292\n",
      "Epoch 7/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - acc: 0.5005 - loss: 1.6135\n",
      "Epoch 8/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - acc: 0.5026 - loss: 1.6080\n",
      "Epoch 9/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - acc: 0.5056 - loss: 1.5907\n",
      "Epoch 10/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - acc: 0.5051 - loss: 1.5947\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step\n",
      "第3个OBC的DNN模型的ROCAUC分数为： 0.5425199089874857\n",
      "第3个OBC的DNN模型的PRAUC分数为： 0.0008582279013728588\n",
      "Epoch 1/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - acc: 0.4995 - loss: 2.0141\n",
      "Epoch 2/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - acc: 0.4971 - loss: 1.6990\n",
      "Epoch 3/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - acc: 0.5000 - loss: 1.6668\n",
      "Epoch 4/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - acc: 0.4992 - loss: 1.6501\n",
      "Epoch 5/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - acc: 0.4994 - loss: 1.6392\n",
      "Epoch 6/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - acc: 0.4997 - loss: 1.6300\n",
      "Epoch 7/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - acc: 0.4993 - loss: 1.6269\n",
      "Epoch 8/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - acc: 0.4982 - loss: 1.6209\n",
      "Epoch 9/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - acc: 0.5007 - loss: 1.6077\n",
      "Epoch 10/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - acc: 0.5083 - loss: 1.5993\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step\n",
      "第4个OBC的DNN模型的ROCAUC分数为： 0.8563708759954494\n",
      "第4个OBC的DNN模型的PRAUC分数为： 0.002274102748669421\n",
      "Epoch 1/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - acc: 0.5010 - loss: 1.8173\n",
      "Epoch 2/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - acc: 0.5048 - loss: 1.6899\n",
      "Epoch 3/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - acc: 0.4980 - loss: 1.6666\n",
      "Epoch 4/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - acc: 0.4986 - loss: 1.6544\n",
      "Epoch 5/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - acc: 0.5016 - loss: 1.6429\n",
      "Epoch 6/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - acc: 0.5037 - loss: 1.6283\n",
      "Epoch 7/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - acc: 0.5000 - loss: 1.6289\n",
      "Epoch 8/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - acc: 0.5028 - loss: 1.6205\n",
      "Epoch 9/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - acc: 0.5056 - loss: 1.6049\n",
      "Epoch 10/10\n",
      "\u001b[1m586/586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - acc: 0.5084 - loss: 1.5962\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step\n",
      "第5个OBC的DNN模型的ROCAUC分数为： 0.4675343147713533\n",
      "第5个OBC的DNN模型的PRAUC分数为： 0.0005545792995308425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————————OBC的DNN模型的最终ROCAUC分数为： 0.5783769946241146 ————————————\n",
      "————————————OBC的DNN模型的最终PRAUC分数为： 0.0009095356037762895 ————————————\n",
      "OBC      0.57\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#feature_list = ['ACF', 'ASA', 'AAINDEX', 'BTA', 'CKSAAP', 'GPS', 'OBC', 'PSEAAC', 'PSSM', 'SS', 'transformer']\n",
    "#feature_list = ['ACF', 'ASA', 'CKSAAP', 'GPS', 'OBC', 'PSEAAC', 'SS', 'transformer']\n",
    "#feature_list = ['transformer']\n",
    "feature_list = ['OBC']\n",
    "#feature_list = ['ACF', 'ASA', 'AAINDEX', 'BTA', 'CKSAAP', 'OBC', 'PSEAAC', 'PSSM', 'SS', 'transformer']\n",
    "model_list = ['DNN']\n",
    "ROCAUC_scores = []\n",
    "PRAUC_scores = []\n",
    "less_than_50 = []\n",
    "training_time_record = {}\n",
    "max_scores = {}\n",
    "if os.path.exists(r'./transfer/models/DNN/reverse_list.txt'):\n",
    "    with open(r'./transfer/models/DNN/reverse_list.txt', mode='r') as t:\n",
    "        reverse_models = t.readlines()\n",
    "        for i, reverse_model in enumerate(reverse_models):\n",
    "            reverse_models[i] = reverse_model.rstrip()\n",
    "else:\n",
    "    reverse_models = []\n",
    "os.chdir(f'E:/NingLab/object/khib/transfer/')\n",
    "for model_type in model_list:\n",
    "    for feature in feature_list:\n",
    "        print('——————————————' + feature + ' ' + model_type + '——————————————')\n",
    "        model1 = get_model('E:/NingLab/object/khib/models/', feature, model_type)\n",
    "        pepID, data, label = prepare_data(feature, model_type)\n",
    "        ppow = 3\n",
    "        learn_rate = pow(0.1, ppow)\n",
    "        #'''\n",
    "        for layer in model1.layers[:-3]:\n",
    "            # print(layer.name)\n",
    "            layer.trainable = False\n",
    "        #'''\n",
    "        # model1.compile(optimizer=Adam(learning_rate=learn_rate), loss='binary_crossentropy', metrics=['acc'])\n",
    "        ROCAUC_score = 0\n",
    "        PRAUC_score = 0\n",
    "        train_time = 1\n",
    "        split = 5\n",
    "        # ROC_threshold = 0.5  # 0.7 for transformer's DNN ;  0.55 for the rest\n",
    "        # PR_threshold = proportion(label)\n",
    "        max_score = 0\n",
    "        # while ROCAUC_score < ROC_threshold:\n",
    "        # while ROCAUC_score < ROC_threshold or PRAUC_score < PR_threshold:\n",
    "        while train_time < 2:\n",
    "            # if chainname == 'M1':\n",
    "            #    skf = StratifiedKFold(n_splits=2, shuffle=False)\n",
    "            # else:\n",
    "            skf = StratifiedKFold(n_splits=split, shuffle=True, random_state=3)\n",
    "            count = 0\n",
    "            y_label = []\n",
    "            y_score = []\n",
    "            peplist = []\n",
    "            best_models = []\n",
    "\n",
    "            for train_index, test_index in skf.split(data, label):\n",
    "                x_train, x_test = data[train_index], data[test_index]\n",
    "                y_train, y_test = label[train_index], label[test_index]\n",
    "                '''\n",
    "                # 训练数据重采样一次，扩增一倍\n",
    "                index_set = []\n",
    "                for index in train_index:\n",
    "                    if y_train[index] == 1:\n",
    "                        index_set.append(index)\n",
    "                x_enrich_positive = data[index_set]\n",
    "                y_enrich_positive = label[index_set]\n",
    "                for nima in range(1, 9):\n",
    "                    np.append(x_train, x_enrich_positive, axis=0)\n",
    "                    np.append(y_train, y_enrich_positive, axis=0)\n",
    "\n",
    "                xy = list(zip(x_train, y_train))\n",
    "                random.shuffle(xy)\n",
    "                x_train[:], y_train[:] = zip(*xy)\n",
    "                # '''\n",
    "                #'''\n",
    "                if model_type == 'DNN':\n",
    "                    #x_resampled, y_resampled = SMOTE().fit_resample(x_train, y_train)\n",
    "                    x_resampled, y_resampled = ADASYN().fit_resample(x_train, y_train)\n",
    "                else:\n",
    "                    x_train_2D = (x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2]))\n",
    "                    x_resampled, y_resampled = SMOTE().fit_resample(x_train_2D, y_train)\n",
    "                    x_resampled = (x_resampled.reshape(x_resampled.shape[0], x_train.shape[1], x_train.shape[2]))\n",
    "                xy = list(zip(x_resampled, y_resampled))\n",
    "                random.shuffle(xy)\n",
    "                x_resampled[:], y_resampled[:] = zip(*xy)\n",
    "                x_train = x_resampled\n",
    "                y_train = y_resampled\n",
    "                # '''\n",
    "\n",
    "                count += 1\n",
    "                y_label.append(list(y_test))\n",
    "                peplist.append(list(pepID[test_index]))\n",
    "\n",
    "                model = clone_model(model1)\n",
    "                model.compile(optimizer=Adam(learning_rate=learn_rate), loss='binary_crossentropy', metrics=['acc'])\n",
    "                '''\n",
    "                model.fit(x_train, y_train, epochs=train_time, batch_size=64, verbose=1,\n",
    "                          class_weight=balance_your_data(y_test)\n",
    "                          )\n",
    "                #'''\n",
    "                model.fit(x_train, y_train, epochs=10, batch_size=64, verbose=1,\n",
    "                          class_weight={0: 1, 1: 10}\n",
    "                          )\n",
    "                y_test_score = model.predict(x_test)\n",
    "                y_score.append(list(y_test_score))\n",
    "\n",
    "                best_models.append(model)\n",
    "\n",
    "                # check roc auc score\n",
    "                rocauc_score = roc_auc_score(y_test, y_test_score)\n",
    "                print(f'第%d个%s的%s模型的ROCAUC分数为：' % (count, feature, model_type),\n",
    "                      rocauc_score)\n",
    "                # check auc score of precision-recall curve\n",
    "                precision, recall, _ = precision_recall_curve(y_test, y_test_score)\n",
    "                prauc_score = auc(recall, precision)\n",
    "                print(f'第%d个%s的%s模型的PRAUC分数为：' % (count, feature, model_type), prauc_score)\n",
    "                reset_keras()\n",
    "\n",
    "            from itertools import chain\n",
    "\n",
    "            peplist1 = []\n",
    "            y_score1 = []\n",
    "            y_label1 = []\n",
    "            peplist = list(chain.from_iterable(peplist))\n",
    "            y_score = list(chain.from_iterable(y_score))\n",
    "            y_label = list(chain.from_iterable(y_label))\n",
    "            for pep in pepID:\n",
    "                peplist1.append(peplist[peplist.index(pep)])\n",
    "                y_score1.append(y_score[peplist.index(pep)])\n",
    "                y_label1.append(y_label[peplist.index(pep)])\n",
    "            ROCAUC_score = roc_auc_score(y_label1, y_score1)\n",
    "            if ROCAUC_score < 0.5:  # reverse scores, record reverse model\n",
    "                if feature not in reverse_models:\n",
    "                    reverse_models.append(feature)\n",
    "                for no, score in enumerate(y_score1):\n",
    "                    y_score1[no] = 1 - score\n",
    "            else:\n",
    "                if feature in reverse_models:\n",
    "                    reverse_models.remove(feature)\n",
    "            ROCAUC_score = roc_auc_score(y_label1, y_score1)\n",
    "\n",
    "            if ROCAUC_score > max_score:\n",
    "                max_score = float(str(ROCAUC_score)[0:4])\n",
    "                max_scores[feature] = max_score\n",
    "                fileplace = f'./models/%s/%s/' % (model_type, feature)\n",
    "                if not os.path.exists(fileplace):\n",
    "                    os.makedirs(fileplace)\n",
    "                for i in range(1, 6):\n",
    "                    best_models[i - 1].save(fileplace + f'%s_%s_%d.h5' % (feature, model_type, i))\n",
    "                df_y = pd.concat([pd.DataFrame(peplist1, columns=['pepname']),\n",
    "                                  pd.DataFrame(y_label1, columns=['label']),\n",
    "                                  pd.DataFrame(y_score1, columns=['score'])], axis=1)\n",
    "                df_y.to_csv(f'./models/%s/%s/%s_y_label&score.csv' % (model_type, feature, feature), index=False)\n",
    "                training_time_record[f'%s_%s' % (feature, model_type)] = train_time\n",
    "\n",
    "            print(f'————————————%s的%s模型的最终ROCAUC分数为：' % (feature, model_type),\n",
    "                  ROCAUC_score, '————————————')\n",
    "\n",
    "            '''\n",
    "            FPR, TPR, _ = roc_curve(y_label1, y_score1)\n",
    "            pyplot.plot(FPR, TPR, marker='.', label=model_type)\n",
    "            pyplot.xlabel('False Positive Rate')\n",
    "            pyplot.ylabel('True Positive Rate')\n",
    "            pyplot.legend()\n",
    "            pyplot.show()\n",
    "            '''\n",
    "\n",
    "            precision, recall, _ = precision_recall_curve(y_label1, y_score1)\n",
    "            PRAUC_score = auc(recall, precision)\n",
    "            print(f'————————————%s的%s模型的最终PRAUC分数为：' % (feature, model_type), PRAUC_score,\n",
    "                  '————————————')\n",
    "            '''\n",
    "            if ROCAUC_score < ROC_threshold:\n",
    "            # if PRAUC_score < PR_threshold or ROCAUC_score < ROC_threshold:\n",
    "                train_time += random.randint(1, 10)\n",
    "                # train_time += 1\n",
    "            # learn_rate += 0.0001\n",
    "            if train_time > 100:  # or ROCAUC_score < 0.45:\n",
    "                train_time = 5\n",
    "                model1 = get_model('E:/QD065LPSc/Ksuc/models', feature, model_type)\n",
    "                for layer in model1.layers[:-3]:\n",
    "                    layer.trainable = False\n",
    "            '''\n",
    "            #train_time += random.randint(1, 10)\n",
    "            train_time += 1\n",
    "        ROCAUC_scores.append(ROCAUC_score)\n",
    "        PRAUC_scores.append(PRAUC_score)\n",
    "with open(r'./models/DNN/reverse_list.txt', mode='w') as textfile:\n",
    "    for reverse_model in reverse_models:\n",
    "        textfile.write(reverse_model + '\\n')\n",
    "for le in less_than_50:\n",
    "    print(le)\n",
    "if os.path.exists('./DNN_train_time.csv'):\n",
    "    original_training_time_record = pd.read_csv('./DNN_train_time.csv')\n",
    "    for record_name in training_time_record.keys():\n",
    "        original_training_time_record[record_name] = training_time_record[record_name]\n",
    "    original_training_time_record.to_csv('./DNN_train_time.csv', index=False)\n",
    "else:\n",
    "    pd.DataFrame(training_time_record, index=[0]).to_csv('./DNN_train_time.csv', index=False)\n",
    "for model_type in max_scores.keys():\n",
    "    print(model_type + '      ' + str(max_scores[model_type]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c007c3d5-da69-44e7-ac79-0777e6356a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a4b8b-23d3-4361-8bff-97c59233a894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
